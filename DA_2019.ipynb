{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from sql import engine\n",
    "import h3\n",
    "\n",
    "pa_data = pd.read_csv('./data/Charging_PA.csv',sep=',')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/sql-practice/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (29,30,32) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "charging_df = pd.DataFrame(pa_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "charging_df.drop(['Start Time Zone','End Time Zone', 'Transaction Date (Pacific Time)',\n",
    "                'GHG Savings (kg)', 'Gasoline Savings (gallons)','Address 1','City', \n",
    "                'State/Province', 'Postal Code', 'Country', 'County', 'System S/N', \n",
    "                'Model Number','Org Name','EVSE ID','Energy (kWh)','Plug Type','Currency'], inplace= True, axis= 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "charging_df.columns = charging_df.columns.str.replace(' ', '_')\n",
    "charging_df.columns = charging_df.columns.str.lower()\n",
    "charging_df.columns = charging_df.columns.str.rstrip()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "charging_df = charging_df.rename(columns={'total_duration_(hh:mm:ss)': 'total_duration', \"charging_time_(hh:mm:ss)\": \"charging_time\"})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "charging_2020 = charging_df.query('start_date >= \"2020-01-01\" & start_date <= \"2020-12-31\"')\n",
    "charging_2019 = charging_df.query('start_date >= \"2019-01-01\" & start_date <= \"2019-12-31\"')\n",
    "charging_2018 = charging_df.query('start_date >= \"2018-01-01\" & start_date <= \"2018-12-31\"')\n",
    "charging_2017 = charging_df.query('start_date >= \"2017-01-01\" & start_date <= \"2017-12-31\"')\n",
    "charging_2016 = charging_df.query('start_date >= \"2016-01-01\" & start_date <= \"2016-12-31\"')\n",
    "charging_2015 = charging_df.query('start_date >= \"2015-01-01\" & start_date <= \"2015-12-31\"')\n",
    "charging_2014 = charging_df.query('start_date >= \"2014-01-01\" & start_date <= \"2014-12-31\"')\n",
    "charging_2013 = charging_df.query('start_date >= \"2013-01-01\" & start_date <= \"2013-12-31\"')\n",
    "charging_2012 = charging_df.query('start_date >= \"2012-01-01\" & start_date <= \"2012-12-31\"')\n",
    "charging_2011 = charging_df.query('start_date >= \"2011-01-01\" & start_date <= \"2011-12-31\"')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Make datetime columns only for 2019\n",
    "date_cols = [\"start_date\", \"end_date\"]\n",
    "duration_cols = [\"total_duration\", \"charging_time\"]\n",
    "\n",
    "for col in date_cols:\n",
    "     charging_2019[date_cols] = charging_2019[date_cols].apply(pd.to_datetime, errors = \"coerce\")\n",
    "\n",
    "\n",
    "for col in duration_cols:\n",
    "     charging_2019[duration_cols] = charging_2019[duration_cols].apply(pd.to_timedelta, errors=\"coerce\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "charging_2019.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 0 entries\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   station_name        0 non-null      object \n",
      " 1   mac_address         0 non-null      object \n",
      " 2   start_date          0 non-null      object \n",
      " 3   end_date            0 non-null      object \n",
      " 4   total_duration      0 non-null      object \n",
      " 5   charging_time       0 non-null      object \n",
      " 6   port_type           0 non-null      object \n",
      " 7   port_number         0 non-null      int64  \n",
      " 8   latitude            0 non-null      float64\n",
      " 9   longitude           0 non-null      float64\n",
      " 10  ended_by            0 non-null      object \n",
      " 11  plug_in_event_id    0 non-null      int64  \n",
      " 12  driver_postal_code  0 non-null      float64\n",
      " 13  user_id             0 non-null      object \n",
      " 14  fee_bol             0 non-null      bool   \n",
      " 15  parking_time        0 non-null      object \n",
      "dtypes: bool(1), float64(3), int64(2), object(10)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# replace NaT in end_date with start_date + total_duration\n",
    "charging_2019['end_date'] = charging_2019['end_date'].fillna((charging_2019['start_date'] + charging_2019['total_duration']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# create column fee_bol (True if user paid, False if charging was free), drop original fee column\n",
    "charging_2019['fee_bol'] = np.where(charging_2019['fee']== 0.0, False, True)\n",
    "charging_2019.drop(['fee'],inplace= True, axis= 1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/sql-practice/lib/python3.8/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# create colum parking_time to display parking time (plugged in but not charging)\n",
    "charging_2019['parking_time'] = charging_2019['total_duration'] - charging_2019['charging_time']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Which year do we want to analyze?\n",
    "\n",
    "unique identifier for each station plug = combination of plug ID and station name"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# create column that displays weekday based on start_date\n",
    "charging_2019['weekday'] = charging_2019['start_date'].dt.dayofweek"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-202811ed20f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create column that displays weekday based on start_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcharging_2019\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weekday'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcharging_2019\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdayofweek\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/sql-practice/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5459\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5460\u001b[0m         ):\n\u001b[0;32m-> 5461\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5462\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/sql-practice/lib/python3.8/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/sql-practice/lib/python3.8/site-packages/pandas/core/indexes/accessors.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mPeriodProperties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .dt accessor with datetimelike values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "charging_2019['weekday'].unique()\n",
    "mymapp = {'0': 'Monday', '1': 'Tuesday', '2': 'Wednesday', '3': 'Thursday', '4': 'Friday', '5': 'Saturday', '6': 'Sunday'}\n",
    "charging_2019.applymap(lambda s: mymapp.get(s) if s in mymapp else s)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def make_weekday_names(row):\n",
    "    if row['weekday'] == 0:\n",
    "        return 'Monday'\n",
    "    if row['weekday'] == 1:\n",
    "        return 'Tuesday'\n",
    "    if row['weekday'] == 2:\n",
    "        return 'Wednesday'\n",
    "    if row['weekday'] == 3:\n",
    "        return 'Thursday'\n",
    "    if row['weekday'] == 4:\n",
    "        return 'Friday'\n",
    "    if row['weekday'] == 5:\n",
    "        return 'Saturday'\n",
    "    if row['weekday'] == 6:\n",
    "        return 'Sunday'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "charging_2019['weekday'] = charging_2019.apply(lambda row : make_weekday_names(row), axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def make_mac_same(row):\n",
    "    return row['mac_address'].replace(':','')\n",
    "\n",
    "charging_2019['mac_address'] = charging_2019.apply(lambda row : make_mac_same(row), axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def make_unique_id(row):\n",
    "    return str(row['mac_address']) + '_' +  str(row['port_number'])\n",
    "\n",
    "charging_2019['unique_plug_id'] = charging_2019.apply(lambda row : make_unique_id(row), axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "charging_2019['index1'] = charging_2019.index"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# change order of columns, put unique_plug_id in front, drop MAC ID\n",
    "charging_2019 = charging_2019[['station_name',\n",
    "                            'unique_plug_id', \n",
    "                            'start_date',\n",
    "                            'end_date',\n",
    "                            'total_duration',\n",
    "                            'charging_time',\n",
    "                            'parking_time',\n",
    "                            'port_type',\n",
    "                            'port_number',\n",
    "                            'latitude',\n",
    "                            'longitude',\n",
    "                            'ended_by', \n",
    "                            'plug_in_event_id',\n",
    "                            'driver_postal_code', \n",
    "                            'user_id',\n",
    "                            'fee_bol', \n",
    "                            'weekday']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "charging_2019 = charging_2019.sort_values(['unique_plug_id', 'start_date'])\n",
    "charging_2019 = charging_2019.reset_index()\n",
    "charging_2019.drop(['index'], inplace= True, axis= 1)\n",
    "charging_2019['idle_time'] = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "max_index = int(len(charging_2019) -1)\n",
    "\n",
    "for index, row in charging_2019.iterrows():\n",
    "    if index >= max_index:\n",
    "        charging_2019['idle_time'][index] = None\n",
    "    elif index <= max_index:\n",
    "        if charging_2019['unique_plug_id'][index+1] != charging_2019['unique_plug_id'][index]:\n",
    "            charging_2019['idle_time'][index] = None\n",
    "        elif charging_2019['unique_plug_id'][index+1] == charging_2019['unique_plug_id'][index]:\n",
    "            charging_2019['idle_time'][index] = charging_2019['start_date'][index+1] - charging_2019['end_date'][index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "duration_cols = [\"idle_time\"]\n",
    "\n",
    "for col in duration_cols:\n",
    "     charging_2019[duration_cols] = charging_2019[duration_cols].apply(pd.to_timedelta, errors=\"coerce\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# bring idle_time to front\n",
    "charging_2019 = charging_2019[['station_name',\n",
    "                            'unique_plug_id', \n",
    "                            'start_date',\n",
    "                            'end_date',\n",
    "                            'total_duration',\n",
    "                            'charging_time',\n",
    "                            'parking_time',\n",
    "                            'idle_time',\n",
    "                            'port_type',\n",
    "                            'port_number',\n",
    "                            'latitude',\n",
    "                            'longitude',\n",
    "                            'ended_by', \n",
    "                            'plug_in_event_id',\n",
    "                            'driver_postal_code', \n",
    "                            'user_id',\n",
    "                            'fee_bol', \n",
    "                            'weekday']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Potential Research Questions\n",
    "\n",
    "Goal: Incentivize consumers in Germany (MUC and surroundings) to buy an EV by providing an optimal charging infrastructure (this means: there is (almost) always a charging station available at the right place (residential, leisure, work)\n",
    "\n",
    "Identifying charging behavior patterns in relation to location specifics - Is Palo Alto a best practice example? If yes, what can other cities (e.g. MUC) learn from them in terms of charging infrastructure?\n",
    "\n",
    "* Impact of COVID -- if time permits\n",
    "* crisis 2013/2014 -- if time permits\n",
    "* identify usage patterns according to location \n",
    "    * What are peak hours? Difference between weekdays / weekends?, per month? per year? \n",
    "    * peak times: How many PA users and how many from outside?\n",
    "    * avg. charging time, avg. parking time, idle times\n",
    "    * How many users are not from PA? What does MUC have to take into account in terms of \"outside\"/\"shuttle\" users?\n",
    "    * Analyze recurring charging customers with zip codes not from PA? Which stations do they use? \n",
    "* What infrastructure strategy is PA using (e.g. how many new stations per year, where? (location characteristics); Is Palo Alto best practice? (define KPIs, what makes a best practice? Ideas: high idle times (even during peak hours or at least other free station nearby), high ratio of charging stations per EV, high coverage?)\n",
    "* How does MUC compare?\n",
    "* Which stations were added newly each year? compare with MUC\n",
    "\n",
    "Potential categories: living, working, shopping, recreation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def make_h3_code(row):\n",
    "    return h3.geo_to_h3(\n",
    "            lat=row['latitude'],\n",
    "            lng=row['longitude'],\n",
    "            resolution=8    # Average Hexagon Area (km2): 0.7373276\n",
    "                            # Average Hexagon Edge Length (km)\n",
    "                            # https://h3geo.org/docs/core-library/restable/\n",
    ")\n",
    "charging_2019['h3_code'] = charging_2019.apply(lambda row : make_h3_code(row), axis=1)\n",
    "charging_2019.h3_code.nunique()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e90ca5e0c4747f62b22fb91b9a1c014c884d23ee898efe3f2ec66be015ea02ff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('sql-practice': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}